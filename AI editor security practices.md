# Protect your sensitive credentials in AI editors like Cursor

Recently we started using cursor in addition to GitHub copilot, and I was personally impressed with how much more productive I could be coding with in addition to GitHub copilot. However there were some things I did not love that I recently ran into so I thought I would share my experience, specifically around .env variables. I recently started a new pet project, and that would specifically leverage a GitHub token, so I created a .env variable, and to my shock AI autocomplete was trying to guess or generate an answer. Despite still having Cursor privacy mode turned on, having a .gitignore with .env file, and even messing with a .cursorignore I expected the AI to ignore my .env similar to GitHub copilot. Apparently, from what I read Cursor has an edge case where is a file is open in the active editor it can still be a target for AI request. I will say Cursor does point out that all data/context/code in privacy mode should be promptly deleted after the request, but this still stressed me out. Luckily I did not open any important project .env files in Cursor, but it
